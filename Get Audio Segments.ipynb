{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from pathlib import Path\n",
    "import subprocess as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/media/Extra_Drive/fushigi'\n",
    "BUCKET = 'fushigi-audio'\n",
    "USERS = ['dane']\n",
    "SEGMENT_LEN = 5  # seconds\n",
    "FFMPEG_PATH = '/usr/bin/ffmpeg'\n",
    "SAMPLE_RATE_WATCH = 8000\n",
    "SAMPLE_RATE_OUT = 8000\n",
    "\n",
    "NNDATA_DIR = '/media/Extra_Drive/fushigi_nn_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.setup_default_session(profile_name='hlnetworks')\n",
    "s3_client = boto3.client('s3')\n",
    "s3_resource = boto3.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each user, create their directory, create subdir for each pcm file, use ffmpeg to generate wavs for each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get users file names.\n",
    "user2keys = {}\n",
    "bucket = s3_resource.Bucket(BUCKET)\n",
    "for o in bucket.objects.all():\n",
    "    if not o.key.endswith('.pcm'):\n",
    "        continue\n",
    "    user = o.key.split('/')[0]\n",
    "    if user not in USERS:\n",
    "        continue\n",
    "    if user not in user2keys:\n",
    "        user2keys[user] = []\n",
    "    user2keys[user].append(o.key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ffmpeg -ar 8000 -f s16le -i url -c copy -f segment -segment_time 30 -ar 8000 -sample_fmt s16 output_%03d.wav\n",
    "def split_s3_audio(url, recording_path):\n",
    "    audio_filepath = str(recording_path/'out%05d.wav')\n",
    "    audio_dl_args = [\n",
    "        FFMPEG_PATH,\n",
    "        '-ar', str(SAMPLE_RATE_WATCH),\n",
    "        '-f', 's16le',\n",
    "        '-i', url,\n",
    "        '-c', 'copy',\n",
    "        '-f', 'segment',\n",
    "        '-segment_time', str(SEGMENT_LEN),\n",
    "        '-ar', str(SAMPLE_RATE_OUT),\n",
    "        '-sample_fmt', 's16',\n",
    "        audio_filepath\n",
    "    ]\n",
    "\n",
    "    proc = sp.Popen(audio_dl_args, stdout=sp.PIPE, stderr=sp.PIPE)\n",
    "    stdout, stderr = proc.communicate()\n",
    "    if proc.returncode != 0:\n",
    "        print(stderr)\n",
    "    else:\n",
    "        print(\"Downloaded audio to \" + audio_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_07_32_50_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_07_38_18_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_07_43_46_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_07_49_14_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_07_54_42_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_08_00_10_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_08_05_38_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_08_11_06_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_08_16_34_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_08_22_02_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_08_27_30_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_08_32_58_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_09_13_38_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_09_19_07_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_09_24_34_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_09_30_02_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_09_35_30_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_09_40_59_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_11_28_52_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_11_34_20_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_11_39_48_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_11_45_16_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_11_56_12_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_12_07_08_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_12_12_36_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_12_25_34_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_12_50_52_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_12_56_20_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_13_09_17_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_13_23_40_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_13_31_08_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_13_34_36_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_13_40_04_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_13_45_32_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_13_52_59_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_14_14_50_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_14_36_41_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_14_58_32_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_15_23_56_20190211.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_16_25_57_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_16_47_49_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_17_09_40_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_17_31_31_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_18_15_13_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_18_37_04_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_18_58_55_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_19_20_46_20190208.pcm/out%05d.wav\n",
      "Downloaded audio to /media/Extra_Drive/fushigi/dane/recording_19_42_37_20190208.pcm/out%05d.wav\n"
     ]
    }
   ],
   "source": [
    "# create dir for user and fnames\n",
    "def get_fname(key):\n",
    "    return key.split('/')[-1]\n",
    "\n",
    "def get_signed_url(s3, bucket):\n",
    "    return s3.generate_presigned_url('get_object', \n",
    "                                     {'Bucket': bucket, 'Key': key})\n",
    "\n",
    "datapath = Path(DATA_DIR)\n",
    "datapath.mkdir(exist_ok=True)\n",
    "for user in USERS:\n",
    "    (datapath/user).mkdir(exist_ok=True)\n",
    "    for key in user2keys[user]:\n",
    "        fname = get_fname(key)\n",
    "        audio_path = datapath/user/fname\n",
    "        (datapath/user/fname).mkdir(exist_ok=True)\n",
    "        url = get_signed_url(s3_client, BUCKET)\n",
    "        split_s3_audio(url, audio_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-6d3ffb03e853>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-6d3ffb03e853>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    import .vggish_input\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import soundfile\n",
    "import librosa\n",
    "\n",
    "import tensorflow as tf\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_postprocess\n",
    "import vggish_slim\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_audio(path):\n",
    "    (audio, fs) = soundfile.read(path)\n",
    "\n",
    "    #if audio.ndim > 1:\n",
    "    #    audio = np.mean(audio, axis=1)\n",
    "        \n",
    "    #if target_fs is not None and fs != target_fs:\n",
    "    #    audio = librosa.resample(audio, orig_sr=fs, target_sr=target_fs)\n",
    "    #    fs = target_fs\n",
    "        \n",
    "    return audio, fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract log mel spectrogram features. \n",
    "\"\"\"\n",
    "\n",
    "# Arguments & parameters\n",
    "#mel_bins = vggish_params.NUM_BANDS\n",
    "#sample_rate = vggish_params.SAMPLE_RATE\n",
    "#input_len = vggish_params.NUM_FRAMES\n",
    "#embedding_size = vggish_params.EMBEDDING_SIZE\n",
    "\n",
    "'''You may modify the EXAMPLE_HOP_SECONDS in vggish_params.py to change the \n",
    "hop size. '''\n",
    "\n",
    "# Paths\n",
    "checkpoint_path = os.path.join('../vggish_model.ckpt')\n",
    "pcm_params_path = os.path.join('../vggish_pca_params.npz')\n",
    "\n",
    "if not os.path.isfile(checkpoint_path):\n",
    "    raise Exception('Please download vggish_model.ckpt from '\n",
    "        'https://storage.googleapis.com/audioset/vggish_model.ckpt '\n",
    "        'and put it in the root of this codebase. ')\n",
    "\n",
    "if not os.path.isfile(pcm_params_path):\n",
    "    raise Exception('Please download pcm_params_path from '\n",
    "    'https://storage.googleapis.com/audioset/vggish_pca_params.npz '\n",
    "    'and put it in the root of this codebase. ')\n",
    "\n",
    "# Load model\n",
    "sess = tf.Session()\n",
    "\n",
    "vggish_slim.define_vggish_slim(training=False)\n",
    "vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
    "features_tensor = sess.graph.get_tensor_by_name(vggish_params.INPUT_TENSOR_NAME)\n",
    "embedding_tensor = sess.graph.get_tensor_by_name(vggish_params.OUTPUT_TENSOR_NAME)\n",
    "\n",
    "pproc = vggish_postprocess.Postprocessor(pcm_params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read audio and map to embeddings\n",
    "outputs = []\n",
    "clip_ids = []\n",
    "errors = []\n",
    "\n",
    "nndata_path = Path(NNDATA_DIR)\n",
    "nndata_path.mkdir(exists_ok=True)\n",
    "\n",
    "for user in USERS:\n",
    "    for key in user2keys[user]:\n",
    "        pcm_fname = get_fname(key)\n",
    "        audio_dir = datapath/user/pcm_fname  # (<-- a directory of wav files)\n",
    "        for wav_fname in os.listdir(audio_dir):\n",
    "            try:\n",
    "                audio_path = os.path.join(audio_dir, wav_fname)\n",
    "                audio, sample_rate = read_audio(audio_path)\n",
    "\n",
    "                # Extract log mel feature\n",
    "                logmel = vggish_input.waveform_to_examples(audio, sample_rate)\n",
    "\n",
    "                # Extract embedding feature\n",
    "                [embedding_batch] = sess.run([embedding_tensor], feed_dict={features_tensor: logmel})\n",
    "\n",
    "                # PCA\n",
    "                postprocessed_batch = pproc.postprocess(embedding_batch)\n",
    "\n",
    "                clip_id = \"%s_%s_%s\" % (user, pcm_fname, wav_fname)\n",
    "                clip_ids.append(clip_id)\n",
    "                outputs.append(postprocessed_batch)\n",
    "            except:\n",
    "                print('error processing: ', str(audio_dir/wav_fname))\n",
    "                errors.append(str(audio_dir/wav_fname))\n",
    "\n",
    "    print('Audio length: {}'.format(len(audio)))\n",
    "    print('Log mel shape: {}'.format(logmel.shape))\n",
    "    print('Embedding feature shape: {}'.format(postprocessed_batch.shape))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audioset_tensorflow",
   "language": "python",
   "name": "audioset_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
